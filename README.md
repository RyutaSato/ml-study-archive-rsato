## How to write commit message
- ğŸ¨ `:art:`: UIã‚„ã‚¹ã‚¿ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°
- âš¡ï¸ `:zap:`: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
- ğŸ› `:bug:`: ãƒã‚°ä¿®æ­£
- ğŸ“ `:memo:`: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚„æ›´æ–°
- ğŸš€ `:rocket:`: æ–°æ©Ÿèƒ½ã®è¿½åŠ 
- ğŸš§ `:construction:`: ä½œæ¥­ä¸­

## Change Log

### 1.2.0ã€€å¯èª­æ€§ã®ãŸã‚ã€æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ­ãƒ¼ã®ã‚¯ãƒ©ã‚¹åã‚’`*Model`ã‹ã‚‰`*Flow`ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚ğŸ’¥ BREAKING CHANGE
- æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ­ãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†ã‹ã‚Šã‚„ã™ãã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’`base_model.py`->`base_flow.py`ã«ã€ã‚¯ãƒ©ã‚¹åã‚’`BaseModel`->`BaseFlow`ã«å¤‰æ›´
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«ãƒ•ãƒ­ãƒ¼ã‚’èµ°ã‚‰ã›ã‚‹å¾“æ¥ã®æ–¹æ³•ã‹ã‚‰ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ãƒ­ãƒ¼ã‚’ç”¨ã„ã‚‹æ–¹æ³•ã«å¤‰æ›´
ã—ãŸãŒã£ã¦ã€ã“ã‚Œã¾ã§ã®`ex_*.py`ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯`DEPRECATED`ã¨ãªã‚Šã¾ã™

### 1.2.1 å…¨ã¦ã®å®Ÿé¨“ã¯ã€`main.py`ã‹ã‚‰å®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«å¤‰æ›´
- `ex_*.py`ã¯å…¨ã¦`DEPRECATED`ã«å¤‰æ›´
- :rocket: new feature `main.py`, `main.yml`, `_main.py`

### 1.2.2 è¦–è¦šåŒ–ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¿½åŠ 

- :rocket: new feature `visualize_utils.py`

## Future Change

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã®å¤‰æ›´
- æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ­ãƒ¼ãŒ`flows`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«çµ±ä¸€ã•ã‚Œã¾ã™ã€‚
- æ©Ÿæ¢°å­¦ç¿’ã«ç›´æ¥é–¢ã‚ã‚Šã®ãªã„Pythonãƒ•ã‚¡ã‚¤ãƒ«ã¯`utils`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«çµ±ä¸€ã•ã‚Œã¾ã™ã€‚
- `ex_*.py`ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€`archive`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã•ã‚Œã¾ã™ã€‚
- å…¨ã¦ã®å®Ÿé¨“ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã€`main.py`ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
- å…¨ã¦ã®å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨è¨­å®šã¯ã€`main.yml`ã«è¨˜è¿°ã—ã¾ã™ã€‚

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã«é–¢ã™ã‚‹è¿½åŠ äºˆå®šæ©Ÿèƒ½

- å¤±æ•—ã—ãŸä¸¦åˆ—ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯`error_params.json`ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
- å®Ÿé¨“ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œå‰ã«ã€`main.yml`ã®validationãŒ`_main.py`ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚
- Git pushå‰ã«å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚

### TODO
- å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’ä½¿ã†
- ç²¾åº¦ã®ã§ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¢ã™


### ç¢ºèªã•ã‚Œã¦ã„ã‚‹ä¸å…·åˆ
- ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ä½¿ç”¨æ™‚ã«ã€å­ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†å¾Œã«GPUãƒ¡ãƒ¢ãƒªãŒè§£æ”¾ã•ã‚Œãªã„
```shell
Traceback (most recent call last):
  File "C:\Users\rsato\anaconda3\envs\ml\lib\concurrent\futures\process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "E:\ml-study-archive-rsato\base_flow.py", line 318, in run
    raise e
  File "E:\ml-study-archive-rsato\base_flow.py", line 310, in run
    self.train_and_predict()
  File "E:\ml-study-archive-rsato\base_flow.py", line 192, in train_and_predict
    _encoder.predict(x_train, verbose=0),  # type: ignore
  File "C:\Users\rsato\anaconda3\envs\ml\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "C:\Users\rsato\anaconda3\envs\ml\lib\site-packages\tensorflow\python\eager\execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;899591e1dcfebd12;/job:localhost/replica:0/task:0/device:GPU:0;edge_11_IteratorGetNext;0:0
	 [[{{node IteratorGetNext/_2}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_predict_function_819156]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\ml-study-archive-rsato\main.py", line 40, in <module>
    main()
  File "E:\ml-study-archive-rsato\main.py", line 36, in main
    logger.info(f"{k} is done: {futures[k].result()}")
  File "C:\Users\rsato\anaconda3\envs\ml\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "C:\Users\rsato\anaconda3\envs\ml\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;899591e1dcfebd12;/job:localhost/replica:0/task:0/device:GPU:0;edge_11_IteratorGetNext;0:0
	 [[{{node IteratorGetNext/_2}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_predict_function_819156]
```
> [!NOTE] è§£æ±ºç­–1
>> GPUè¨ˆç®—ç”¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’ï¼‘ã¤ã®ã¿ç”¨æ„ã—ã€Queueã§è¨ˆç®—ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å–å¾—ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€CPUã®ã¿ã§æ¼”ç®—ã™ã‚‹ã€‚

> è§£æ±ºç­–2
>> å„`executor`ã‚’å®Ÿè¡Œå¾Œã«ã€`del`ã‚’å‘¼ã³å‡ºã™ã€‚

> è§£æ±ºç­–3
>> ãƒ—ãƒ­ã‚»ã‚¹æ•°ã‚’å›ºå®šã—ã€Queueã«è¨ˆç®—ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŠ•ã’ã€å–å¾—ã—ãŸãƒ—ãƒ­ã‚»ã‚¹ãŒå®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã™ã‚‹ã€‚
>> ãã®éš›ã«ã€å„ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€ç ´å£Šçš„ãƒ¡ã‚½ãƒƒãƒ‰ã§å†…éƒ¨ã‚’å®šç¾©ã™ã‚‹ã“ã¨ï¼

- ä¸å®šæœŸã«é…åˆ—ã‚µã‚¤ã‚ºã®ä¸ä¸€è‡´ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã€‚(åŸå› ä¸æ˜)
```sh
Shape of passed values is (a1, b1), indices imply (a2, b2)
```